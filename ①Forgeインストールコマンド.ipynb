{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e42bc1e-9825-4587-b533-c74607b1a377",
   "metadata": {},
   "source": [
    "## モデルアニメ系\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6381569a-51b4-4303-a623-7f0b70104889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T21:39:41.907089Z",
     "iopub.status.busy": "2024-12-12T21:39:41.906370Z",
     "iopub.status.idle": "2024-12-12T21:39:44.276664Z",
     "shell.execute_reply": "2024-12-12T21:39:44.276129Z",
     "shell.execute_reply.started": "2024-12-12T21:39:41.907064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n",
      "Cloning into 'stable-diffusion-webui-forge'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 41771, done.\u001b[K\n",
      "remote: Counting objects: 100% (10716/10716), done.\u001b[K\n",
      "remote: Compressing objects: 100% (817/817), done.\u001b[K\n",
      "remote: Total 41771 (delta 10064), reused 9910 (delta 9897), pack-reused 31055 (from 1)\u001b[K\n",
      "Receiving objects: 100% (41771/41771), 46.11 MiB | 50.07 MiB/s, done.\n",
      "Resolving deltas: 100% (29091/29091), done.\n"
     ]
    }
   ],
   "source": [
    "# /tmpディレクトリに移動します\n",
    "%cd /tmp\n",
    "!git clone https://github.com/lllyasviel/stable-diffusion-webui-forge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549702e-7e03-478a-9ccb-49d76de1d80e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:11:23.455562Z",
     "iopub.status.busy": "2024-12-12T22:11:23.454865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "Version: f2.0.1v1.10.1-previous-633-ge073e4ec\n",
      "Commit hash: e073e4ec581c803cbc71003f6d3261d37ec43840\n",
      "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
      "Launching Web UI with arguments: --enable-insecure-extension-access --gradio-queue --share\n",
      "Total VRAM 16109 MB, total RAM 45140 MB\n",
      "pytorch version: 2.4.1+cu124\n",
      "xformers version: 0.0.28.post1\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA RTX A4000 : native\n",
      "Hint: your device supports --cuda-malloc for potential speed improvements.\n",
      "VAE dtype preferences: [torch.bfloat16, torch.float32] -> torch.bfloat16\n",
      "CUDA Using Stream: False\n",
      "2024-12-12 22:11:34.293823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 22:11:35.144518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using xformers cross attention\n",
      "Using xformers attention for VAE\n",
      "ControlNet preprocessor location: /tmp/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
      "<module 'scripts' (<_frozen_importlib_external._NamespaceLoader object at 0x7fba34d8abc0>)> None ['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'deforum_api', 'deforum_api_models', 'deforum_extend_paths']\n",
      "Loading additional modules ... done.\n",
      "2024-12-12 22:11:55,176 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
      "Checkpoint cat-tower-noobai-xl-checkpoint-v14vpred-sdxl/text_encoder/model.safetensors not found; loading fallback cat-tower-noobai-xl-checkpoint-v14vpred-sdxl.safetensors [64eaf97ce9]\n",
      "Model selected: {'checkpoint_info': {'filename': '/tmp/stable-diffusion-webui-forge/models/Stable-diffusion/cat-tower-noobai-xl-checkpoint-v14vpred-sdxl.safetensors', 'hash': '8e8cd981'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
      "Using online LoRAs in FP16: False\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://8a0c1b7cec99c81653.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Startup time: 36.2s (prepare environment: 3.4s, launcher: 0.4s, import torch: 12.7s, other imports: 0.1s, load scripts: 2.7s, initialize google blockly: 11.4s, create ui: 3.0s, gradio launch: 2.4s).\n",
      "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
      "[GPU Setting] You will use 93.64% GPU memory (15084.00 MB) to load weights, and use 6.36% GPU memory (1024.00 MB) to do matrix computation.\n",
      "[TIPO-KGen]-|22:12:48|-\u001b[0;32mINFO\u001b[0m: Llama-cpp-python/gguf model TIPO-200M-ft_TIPO-200M-ft-F16.gguf loaded\n",
      "[TIPO-KGen]-|22:12:48|-\u001b[0;33mWARNING\u001b[0m: llama.cpp have reproducibility issue on cuda (https://github.com/ggerganov/llama.cpp/pull/1346) It is suggested to use cpu or compile llama-cpp-python by yourself and set GGML_CUDA_MAX_STREAMS in the file ggml-cuda.cu to 1.\n",
      "[TIPO-KGen]-|22:12:48|-\u001b[0;32mINFO\u001b[0m: Processing propmt: ...\n",
      "[TIPO-KGen]-|22:12:48|-\u001b[0;32mINFO\u001b[0m: Processing with seed: 34935016\n",
      "[TIPO-KGen]-|22:12:57|-\u001b[0;32mINFO\u001b[0m: Prompt processing done.\n",
      "[TIPO-KGen]-|22:14:03|-\u001b[0;32mINFO\u001b[0m: Processing propmt: (very young female child:1.2),(solo:1.1)...\n",
      "[TIPO-KGen]-|22:14:03|-\u001b[0;32mINFO\u001b[0m: Processing with seed: 1105043072\n",
      "[TIPO-KGen]-|22:14:11|-\u001b[0;32mINFO\u001b[0m: Prompt processing done.\n",
      "Loading Model: {'checkpoint_info': {'filename': '/tmp/stable-diffusion-webui-forge/models/Stable-diffusion/cat-tower-noobai-xl-checkpoint-v14vpred-sdxl.safetensors', 'hash': '8e8cd981'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
      "[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.\n",
      "StateDict Keys: {'unet': 1680, 'vae': 248, 'text_encoder': 196, 'text_encoder_2': 517, 'ignore': 0}\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "K-Model Created: {'storage_dtype': torch.float16, 'computation_dtype': torch.float16}\n",
      "Model loaded in 1.9s (unload existing model: 0.7s, forge model load: 1.2s).\n",
      "[Unload] Trying to free 3051.58 MB for cuda:0 with 0 models keep loaded ... Done.\n",
      "[Memory Management] Target: JointTextEncoder, Free GPU: 14385.02 MB, Model Require: 1559.68 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 11801.34 MB, All loaded to GPU.\n",
      "Moving model(s) has taken 0.25 seconds\n",
      "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 12607.32 MB ... Done.\n",
      "[Unload] Trying to free 7656.40 MB for cuda:0 with 0 models keep loaded ... Current free memory is 12605.06 MB ... Done.\n",
      "[Memory Management] Target: KModel, Free GPU: 12605.06 MB, Model Require: 4897.05 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6684.01 MB, All loaded to GPU.\n",
      "Moving model(s) has taken 1.02 seconds\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|##2                                         | 1/20 [00:01<00:24,  1.28s/it]\u001b[A\n",
      " 10%|####4                                       | 2/20 [00:01<00:13,  1.37it/s]\u001b[A\n",
      " 15%|######6                                     | 3/20 [00:01<00:09,  1.81it/s]\u001b[A\n",
      " 20%|########8                                   | 4/20 [00:02<00:07,  2.13it/s]\u001b[A\n",
      " 25%|###########                                 | 5/20 [00:02<00:06,  2.37it/s]\u001b[A\n",
      " 30%|#############2                              | 6/20 [00:03<00:05,  2.49it/s]\u001b[A\n",
      " 35%|###############4                            | 7/20 [00:03<00:05,  2.45it/s]\u001b[A\n",
      " 40%|#################6                          | 8/20 [00:03<00:04,  2.49it/s]\u001b[A\n",
      " 45%|###################8                        | 9/20 [00:04<00:04,  2.60it/s]\u001b[A\n",
      " 50%|#####################5                     | 10/20 [00:04<00:03,  2.65it/s]\u001b[A\n",
      " 55%|#######################6                   | 11/20 [00:04<00:03,  2.70it/s]\u001b[A\n",
      " 60%|#########################8                 | 12/20 [00:05<00:02,  2.75it/s]\u001b[A\n",
      " 65%|###########################9               | 13/20 [00:05<00:02,  2.76it/s]\u001b[A\n",
      " 70%|##############################1            | 14/20 [00:05<00:02,  2.79it/s]\u001b[A\n",
      " 75%|################################2          | 15/20 [00:06<00:01,  2.80it/s]\u001b[A\n",
      " 80%|##################################4        | 16/20 [00:06<00:01,  2.82it/s]\u001b[A\n",
      " 85%|####################################5      | 17/20 [00:06<00:01,  2.82it/s]\u001b[A\n",
      " 90%|######################################7    | 18/20 [00:07<00:00,  2.85it/s]\u001b[A\n",
      " 95%|########################################8  | 19/20 [00:07<00:00,  2.87it/s]\u001b[A\n",
      "100%|###########################################| 20/20 [00:08<00:00,  2.49it/s]\u001b[A\n",
      "[Unload] Trying to free 4495.36 MB for cuda:0 with 0 models keep loaded ... Current free memory is 7293.91 MB ... Done.\n",
      "[Memory Management] Target: IntegratedAutoencoderKL, Free GPU: 7293.91 MB, Model Require: 159.56 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6110.35 MB, All loaded to GPU.\n",
      "Moving model(s) has taken 0.07 seconds\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 20/20 [00:08<00:00,  2.40it/s]\u001b[A\n",
      "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7095.34 MB ... Done.\n",
      "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7094.73 MB ... Done.\n",
      "[Unload] Trying to free 1290.24 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.59 MB ... Done.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|##2                                         | 1/20 [00:00<00:06,  2.99it/s]\u001b[A\n",
      " 10%|####4                                       | 2/20 [00:00<00:06,  2.98it/s]\u001b[A\n",
      " 15%|######6                                     | 3/20 [00:01<00:05,  2.94it/s]\u001b[A\n",
      " 20%|########8                                   | 4/20 [00:01<00:05,  2.94it/s]\u001b[A\n",
      " 25%|###########                                 | 5/20 [00:01<00:05,  2.94it/s]\u001b[A\n",
      " 30%|#############2                              | 6/20 [00:02<00:04,  2.92it/s]\u001b[A\n",
      " 35%|###############4                            | 7/20 [00:02<00:04,  2.91it/s]\u001b[A\n",
      " 40%|#################6                          | 8/20 [00:02<00:04,  2.91it/s]\u001b[A\n",
      " 45%|###################8                        | 9/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 50%|#####################5                     | 10/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 55%|#######################6                   | 11/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 60%|#########################8                 | 12/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 65%|###########################9               | 13/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 70%|##############################1            | 14/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 75%|################################2          | 15/20 [00:05<00:01,  2.89it/s]\u001b[A\n",
      " 80%|##################################4        | 16/20 [00:05<00:01,  2.89it/s]\u001b[A\n",
      " 85%|####################################5      | 17/20 [00:05<00:01,  2.89it/s]\u001b[A\n",
      " 90%|######################################7    | 18/20 [00:06<00:00,  2.89it/s]\u001b[A\n",
      " 95%|########################################8  | 19/20 [00:06<00:00,  2.88it/s]\u001b[A\n",
      "100%|###########################################| 20/20 [00:06<00:00,  2.90it/s]\u001b[A\n",
      "[Unload] Trying to free 4287.94 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.10 MB ... Done.\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 20/20 [00:07<00:00,  2.66it/s]\u001b[A\n",
      "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.84 MB ... Done.\n",
      "[Unload] Trying to free 1290.24 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.59 MB ... Done.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|##2                                         | 1/20 [00:00<00:06,  3.00it/s]\u001b[A\n",
      " 10%|####4                                       | 2/20 [00:00<00:06,  2.98it/s]\u001b[A\n",
      " 15%|######6                                     | 3/20 [00:01<00:05,  2.94it/s]\u001b[A\n",
      " 20%|########8                                   | 4/20 [00:01<00:05,  2.95it/s]\u001b[A\n",
      " 25%|###########                                 | 5/20 [00:01<00:05,  2.95it/s]\u001b[A\n",
      " 30%|#############2                              | 6/20 [00:02<00:04,  2.93it/s]\u001b[A\n",
      " 35%|###############4                            | 7/20 [00:02<00:04,  2.94it/s]\u001b[A\n",
      " 40%|#################6                          | 8/20 [00:02<00:04,  2.94it/s]\u001b[A\n",
      " 45%|###################8                        | 9/20 [00:03<00:03,  2.93it/s]\u001b[A\n",
      " 50%|#####################5                     | 10/20 [00:03<00:03,  2.93it/s]\u001b[A\n",
      " 55%|#######################6                   | 11/20 [00:03<00:03,  2.93it/s]\u001b[A\n",
      " 60%|#########################8                 | 12/20 [00:04<00:02,  2.90it/s]\u001b[A\n",
      " 65%|###########################9               | 13/20 [00:04<00:02,  2.90it/s]\u001b[A\n",
      " 70%|##############################1            | 14/20 [00:04<00:02,  2.90it/s]\u001b[A\n",
      " 75%|################################2          | 15/20 [00:05<00:01,  2.90it/s]\u001b[A\n",
      " 80%|##################################4        | 16/20 [00:05<00:01,  2.90it/s]\u001b[A\n",
      " 85%|####################################5      | 17/20 [00:05<00:01,  2.90it/s]\u001b[A\n",
      " 90%|######################################7    | 18/20 [00:06<00:00,  2.90it/s]\u001b[A\n",
      " 95%|########################################8  | 19/20 [00:06<00:00,  2.90it/s]\u001b[A\n",
      "100%|###########################################| 20/20 [00:06<00:00,  2.92it/s]\u001b[A\n",
      "[Unload] Trying to free 4287.94 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.10 MB ... Done.\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 20/20 [00:07<00:00,  2.69it/s]\u001b[A\n",
      "[Unload] Trying to free 1290.24 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.10 MB ... Done.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|##2                                         | 1/20 [00:00<00:06,  2.96it/s]\u001b[A\n",
      " 10%|####4                                       | 2/20 [00:00<00:06,  2.95it/s]\u001b[A\n",
      " 15%|######6                                     | 3/20 [00:01<00:05,  2.92it/s]\u001b[A\n",
      " 20%|########8                                   | 4/20 [00:01<00:05,  2.92it/s]\u001b[A\n",
      " 25%|###########                                 | 5/20 [00:01<00:05,  2.92it/s]\u001b[A\n",
      " 30%|#############2                              | 6/20 [00:02<00:04,  2.90it/s]\u001b[A\n",
      " 35%|###############4                            | 7/20 [00:02<00:04,  2.91it/s]\u001b[A\n",
      " 40%|#################6                          | 8/20 [00:02<00:04,  2.90it/s]\u001b[A\n",
      " 45%|###################8                        | 9/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 50%|#####################5                     | 10/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 55%|#######################6                   | 11/20 [00:03<00:03,  2.90it/s]\u001b[A\n",
      " 60%|#########################8                 | 12/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 65%|###########################9               | 13/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 70%|##############################1            | 14/20 [00:04<00:02,  2.89it/s]\u001b[A\n",
      " 75%|################################2          | 15/20 [00:05<00:01,  2.89it/s]\u001b[A\n",
      " 80%|##################################4        | 16/20 [00:05<00:01,  2.88it/s]\u001b[A\n",
      " 85%|####################################5      | 17/20 [00:05<00:01,  2.88it/s]\u001b[A\n",
      " 90%|######################################7    | 18/20 [00:06<00:00,  2.89it/s]\u001b[A\n",
      " 95%|########################################8  | 19/20 [00:06<00:00,  2.88it/s]\u001b[A\n",
      "100%|###########################################| 20/20 [00:06<00:00,  2.89it/s]\u001b[A\n",
      "[Unload] Trying to free 4287.94 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7091.61 MB ... Done.\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 20/20 [00:08<00:00,  2.45it/s]\u001b[A\n",
      "[Unload] Trying to free 1290.24 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.59 MB ... Done.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|##2                                         | 1/20 [00:00<00:06,  2.94it/s]\u001b[A\n",
      " 10%|####4                                       | 2/20 [00:00<00:06,  2.91it/s]\u001b[A\n",
      " 15%|######6                                     | 3/20 [00:01<00:05,  2.87it/s]\u001b[A\n",
      " 20%|########8                                   | 4/20 [00:01<00:05,  2.88it/s]\u001b[A\n",
      " 25%|###########                                 | 5/20 [00:01<00:05,  2.89it/s]\u001b[A\n",
      " 30%|#############2                              | 6/20 [00:02<00:04,  2.88it/s]\u001b[A\n",
      " 35%|###############4                            | 7/20 [00:02<00:04,  2.89it/s]\u001b[A\n",
      " 40%|#################6                          | 8/20 [00:02<00:04,  2.89it/s]\u001b[A\n",
      " 45%|###################8                        | 9/20 [00:03<00:03,  2.89it/s]\u001b[A\n",
      " 50%|#####################5                     | 10/20 [00:03<00:03,  2.89it/s]\u001b[A\n",
      " 55%|#######################6                   | 11/20 [00:03<00:03,  2.88it/s]\u001b[A\n",
      " 60%|#########################8                 | 12/20 [00:04<00:02,  2.88it/s]\u001b[A\n",
      " 65%|###########################9               | 13/20 [00:04<00:02,  2.88it/s]\u001b[A\n",
      " 70%|##############################1            | 14/20 [00:04<00:02,  2.88it/s]\u001b[A\n",
      " 75%|################################2          | 15/20 [00:05<00:01,  2.88it/s]\u001b[A\n",
      " 80%|##################################4        | 16/20 [00:05<00:01,  2.88it/s]\u001b[A\n",
      " 85%|####################################5      | 17/20 [00:05<00:01,  2.88it/s]\u001b[A\n",
      " 90%|######################################7    | 18/20 [00:06<00:00,  2.88it/s]\u001b[A\n",
      " 95%|########################################8  | 19/20 [00:06<00:00,  2.87it/s]\u001b[A\n",
      "100%|###########################################| 20/20 [00:06<00:00,  2.88it/s]\u001b[A\n",
      "[Unload] Trying to free 4287.94 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7092.10 MB ... Done.\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 20/20 [00:08<00:00,  2.45it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# /tmp/stable-diffusion-webuiディレクトリに移動してlaunch.pyを実行\n",
    "!cd /tmp/stable-diffusion-webui-forge && python3 launch.py --enable-insecure-extension-access --gradio-queue --share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f92c32-d3ea-4b0a-888f-545bd66e1139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T21:39:49.948080Z",
     "iopub.status.busy": "2024-12-12T21:39:49.947357Z",
     "iopub.status.idle": "2024-12-12T21:39:50.279692Z",
     "shell.execute_reply": "2024-12-12T21:39:50.278954Z",
     "shell.execute_reply.started": "2024-12-12T21:39:49.948057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/stable-diffusion-webui-forge\n",
      "Checking patch backend/modules/k_prediction.py...\n",
      "error: while searching for:\n",
      "import math\n",
      "import torch\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
      "\n",
      "error: patch failed: backend/modules/k_prediction.py:1\n",
      "Hunk #2 succeeded at 67 (offset 17 lines).\n",
      "Checking patch modules/shared_options.py...\n",
      "Hunk #1 succeeded at 392 (offset 2 lines).\n",
      "Applying patch backend/modules/k_prediction.py with 1 reject...\n",
      "Rejected hunk #1.\n",
      "Hunk #2 applied cleanly.\n",
      "Applied patch modules/shared_options.py cleanly.\n"
     ]
    }
   ],
   "source": [
    "!cp /notebooks/prediction.txt /tmp/stable-diffusion-webui-forge\n",
    "%cd /tmp/stable-diffusion-webui-forge\n",
    "!git apply --reject /notebooks/prediction.txt\n",
    "\n",
    "!sed -i '/import numpy as np/a\\from modules.shared import opts' /tmp/stable-diffusion-webui-forge/backend/modules/k_prediction.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500a4be4-866e-41d5-a675-14c0439de90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:08:54.467456Z",
     "iopub.status.busy": "2024-11-24T18:08:54.466892Z",
     "iopub.status.idle": "2024-11-24T18:08:54.584631Z",
     "shell.execute_reply": "2024-11-24T18:08:54.583958Z",
     "shell.execute_reply.started": "2024-11-24T18:08:54.467427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/stable-diffusion-webui-forge\n",
      "Checking patch backend/modules/k_prediction.py...\n",
      "error: while searching for:\n",
      "import math\n",
      "import torch\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
      "\n",
      "error: patch failed: backend/modules/k_prediction.py:1\n",
      "Hunk #2 succeeded at 67 (offset 17 lines).\n",
      "Checking patch modules/shared_options.py...\n",
      "Hunk #1 succeeded at 391 (offset 1 line).\n",
      "Applying patch backend/modules/k_prediction.py with 1 reject...\n",
      "Rejected hunk #1.\n",
      "Hunk #2 applied cleanly.\n",
      "Applied patch modules/shared_options.py cleanly.\n"
     ]
    }
   ],
   "source": [
    "%cd /tmp/stable-diffusion-webui-forge\n",
    "!git apply --reject /notebooks/prediction.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1778e1ff-2cd8-4ae6-aa34-7fa463766232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:08:56.595024Z",
     "iopub.status.busy": "2024-11-24T18:08:56.594307Z",
     "iopub.status.idle": "2024-11-24T18:08:56.708933Z",
     "shell.execute_reply": "2024-11-24T18:08:56.708132Z",
     "shell.execute_reply.started": "2024-11-24T18:08:56.594995Z"
    }
   },
   "outputs": [],
   "source": [
    "!sed -i '/import numpy as np/a\\from modules.shared import opts' /tmp/stable-diffusion-webui-forge/backend/modules/k_prediction.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2234b0b-2882-474b-8864-ef71633ededc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T19:00:05.785104Z",
     "iopub.status.busy": "2024-11-19T19:00:05.784212Z",
     "iopub.status.idle": "2024-11-19T19:00:05.897117Z",
     "shell.execute_reply": "2024-11-19T19:00:05.896347Z",
     "shell.execute_reply.started": "2024-11-19T19:00:05.785072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff a/backend/modules/k_prediction.py b/backend/modules/k_prediction.py\t(rejected hunks)\n",
      "@@ -1,6 +1,8 @@\n",
      " import math\n",
      " import torch\n",
      " import numpy as np\n",
      "+from modules.shared import opts\n",
      "+\n",
      " \n",
      " \n",
      " def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/stable-diffusion-webui-forge/backend/modules/k_prediction.py.rej\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e5d1d5-3ca5-4647-a2d7-d2f793a2a2f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T18:59:55.857860Z",
     "iopub.status.busy": "2024-11-19T18:59:55.857474Z",
     "iopub.status.idle": "2024-11-19T18:59:55.972383Z",
     "shell.execute_reply": "2024-11-19T18:59:55.971545Z",
     "shell.execute_reply.started": "2024-11-19T18:59:55.857835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from modules.shared import opts\n"
     ]
    }
   ],
   "source": [
    "!grep 'from modules.shared import opts' /tmp/stable-diffusion-webui-forge/backend/modules/k_prediction.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
